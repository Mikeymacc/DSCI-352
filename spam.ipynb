{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6666b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "26    0\n",
      "27    0\n",
      "28    0\n",
      "29    0\n",
      "30    0\n",
      "31    0\n",
      "32    0\n",
      "33    0\n",
      "34    0\n",
      "35    0\n",
      "36    0\n",
      "37    0\n",
      "38    0\n",
      "39    0\n",
      "40    0\n",
      "41    0\n",
      "42    0\n",
      "43    0\n",
      "44    0\n",
      "45    0\n",
      "46    0\n",
      "47    0\n",
      "48    0\n",
      "49    0\n",
      "50    0\n",
      "51    0\n",
      "52    0\n",
      "53    0\n",
      "54    0\n",
      "55    0\n",
      "56    0\n",
      "57    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# reads in data\n",
    "data = pd.read_csv(\"spambase.data\", header=None)\n",
    "\n",
    "# gets fetaures and last column as target\n",
    "x = data.iloc[:, :-1]  # All columns except the last\n",
    "y = data.iloc[:, -1]   # Last column\n",
    "\n",
    "# missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# standardizes the features\n",
    "scaler = StandardScaler()\n",
    "xscale = scaler.fit_transform(x)\n",
    "\n",
    "# splist the dtat set 90% to training and 10% to testing\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(xscale, y, test_size=0.1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d120aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Precision, Recall for each model:\n",
      " [[0.93926247 0.94736842 0.90909091]\n",
      " [0.92624729 0.89805825 0.93434343]\n",
      " [0.93709328 0.93333333 0.91919192]\n",
      " [0.9197397  0.90452261 0.90909091]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# function trains the models and records the metrics\n",
    "def train(model, xtrain, ytrain, xtest, ytest):\n",
    "    model.fit(xtrain, ytrain)\n",
    "    ypred = model.predict(xtest)\n",
    "    accuracy = accuracy_score(ytest, ypred)\n",
    "    precision = precision_score(ytest, ypred)\n",
    "    recall = recall_score(ytest, ypred)\n",
    "    return [accuracy, precision, recall]\n",
    "\n",
    "# these are the different type of models we will be evaluating\n",
    "models = [\n",
    "    MLPClassifier(hidden_layer_sizes=(5,), activation='logistic', max_iter=1000, random_state=0),\n",
    "    MLPClassifier(hidden_layer_sizes=(10, 10), activation='logistic', max_iter=1000, random_state=0),\n",
    "    MLPClassifier(hidden_layer_sizes=(5,), activation='relu', max_iter=1000, random_state=0),\n",
    "    MLPClassifier(hidden_layer_sizes=(10, 10), activation='relu', max_iter=1000, random_state=0)\n",
    "]\n",
    "\n",
    "# results array\n",
    "results = np.zeros((4, 3))\n",
    "\n",
    "# for each model it trains and gives results\n",
    "for i, model in enumerate(models):\n",
    "    results[i] = train(model, xtrain, ytrain, xtest, ytest)\n",
    "\n",
    "# results\n",
    "print(\"Accuracy, Precision, Recall for each model:\\n\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f93e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Discussion:\n",
    "\n",
    "1. Warnings:\n",
    "   My code did not produce any significant warnings except for an iteration warning in some cases when I was testing for best models. \n",
    "   For example, some models may produce a convergence warning when using `MLPClassifier`. \n",
    "   This happens when the model fails to converge within the specified number of iterations (ie max_iter = 1000).\n",
    "   This issue was more common in models with thats more complex (with mor ehidden layers) because these models require more iterations to converge compared to simpler ones (single layers and less neurons).\n",
    "   \n",
    "2. Precision vs. Recall in Spam Email Classification:\n",
    "   Precision is more important than recall in a spam email learning task because precision measures how many emails classified as spam are actually spam. In this context, it's more critical to minimize false positives since users would be more frustrated if important emails were wrongly classified as spam and sent to the spam folder.\n",
    "   On the other hand, recall measures how many actual spam emails are correctly classified. While recall is important, missing some spam, false negatives, is generally more acceptable than incorrectly classifying legitimate emails as spam (false positives).\n",
    "   \n",
    "   This is a tradeoff: If we aim to improve precision, we may reduce recall. Conversely, improving recall might reduce precision, leading to more false positives. Hence, the best model depends on how sensitive we want to be to false positives (low precision) vs. false negatives (low recall).\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "174969c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonus model performance: Accuracy, Precision, Recall\n",
      " [0.9414316702819957, 0.9384615384615385, 0.9242424242424242]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bonusmodel = MLPClassifier(hidden_layer_sizes=(5,), activation='relu', max_iter=1000, learning_rate_init=0.0005, alpha=0.0001, random_state=0)\n",
    "\n",
    "bonusmodel.fit(xtrain, ytrain)\n",
    "\n",
    "bonusy_pred = bonusmodel.predict(xtest)\n",
    "\n",
    "bonusmetrics = [\n",
    "    accuracy_score(ytest, bonusy_pred),\n",
    "    precision_score(ytest, bonusy_pred),\n",
    "    recall_score(ytest, bonusy_pred)\n",
    "]\n",
    "\n",
    "# results\n",
    "print(\"Bonus model performance: Accuracy, Precision, Recall\\n\", bonusmetrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2595d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
