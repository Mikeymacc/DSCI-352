{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0cc853c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns removed: ['monthapr', 'monthdec', 'monthfeb', 'monthjan', 'monthjun', 'monthmay', 'monthnov', 'monthoct']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import numpy as np\n",
    "\n",
    "# load in dataset\n",
    "data = pd.read_csv('forestfires.csv')  \n",
    "\n",
    "# checks for missing values\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "missvalues = data.isnull().sum().sum()\n",
    "\n",
    "# handle missing values if any are found\n",
    "if missvalues > 0:\n",
    "    data.dropna(inplace=True)  # removes rows with missing values\n",
    "\n",
    "# encodes the non-numeric columns in the data set\n",
    "nonnumeric_col = data.select_dtypes(include=['object']).columns\n",
    "labelen = {}\n",
    "for column in nonnumeric_col:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    labelen[column] = le  # stores encoder\n",
    "\n",
    "# last column is the target\n",
    "target = data.columns[-1]\n",
    "x = data.drop(columns=[target])\n",
    "y = data[target]\n",
    "\n",
    "# applies variance thresholding to remove low-variance features\n",
    "threshold = 0.05 \n",
    "selector = VarianceThreshold(threshold=threshold)\n",
    "xreduced = selector.fit_transform(x)\n",
    "\n",
    "# listed of removed columns and updates x\n",
    "removed = x.columns[~selector.get_support()].tolist()\n",
    "print(\"Columns removed:\", removed)\n",
    "x = x.loc[:, selector.get_support()]\n",
    "\n",
    "# standardizes features\n",
    "scaler = StandardScaler()\n",
    "xscaled = scaler.fit_transform(X)\n",
    "\n",
    "# make target variable as binary\n",
    "yencoder = LabelEncoder()\n",
    "y = yencoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1449962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      " [[0.94615385 0.93       1.         0.96373057]\n",
      " [0.96923077 0.97849462 0.97849462 0.97849462]\n",
      " [0.96923077 0.97849462 0.97849462 0.97849462]\n",
      " [0.91538462 0.91       0.97849462 0.94300518]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# splits data into training and testing sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(xscaled, y, test_size=0.25, random_state=0)\n",
    "\n",
    "kernels = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "paramgrid = {\n",
    "    'C': [1000, 100, 10, 1, 0.1, 0.001],\n",
    "    'gamma': [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    model = SVC(kernel=kernel, random_state=0)\n",
    "    \n",
    "    # adds degree parameter if using polynomial\n",
    "    if kernel == 'poly':\n",
    "        paramgrid['degree'] = [1, 2, 3, 4]\n",
    "    else:\n",
    "        paramgrid.pop('degree', None)\n",
    "    \n",
    "    # uses GridSearchCV to find best parameters for the model\n",
    "    grid = GridSearchCV(model, paramgrid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    grid.fit(xtrain, ytrain)\n",
    "    \n",
    "    # finds best model with selected parameters\n",
    "    bestmodel = grid.best_estimator_\n",
    "    ypred = bestmodel.predict(xtest)\n",
    "    \n",
    "    # gets the metrics\n",
    "    acc = accuracy_score(y_test, ypred)\n",
    "    prec = precision_score(y_test, ypred, average='binary', pos_label=1)\n",
    "    rec = recall_score(y_test, ypred, average='binary', pos_label=1)\n",
    "    f1 = f1_score(y_test, ypred, average='binary', pos_label=1)\n",
    "    \n",
    "    # add results\n",
    "    results.append([acc, prec, rec, f1])\n",
    "\n",
    "# coverts to a 4x4 array\n",
    "resultsarr = np.array(results)\n",
    "print(\"Results:\\n\", resultsarr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "557192e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n1. Did your code produce any warnings? What were they? \\n   Why do you think this may have happened for some models but not for others?\\n\\n   The code did not produce any warnings for me. This suggests that all kernels and parameter ranges were compatible with \\n   the dataset and my device, allowing the models to converge without any visible issues. Warnings might typically occur if a model struggles \\n   with complex boundaries (like higher-degree polynomial kernels), but here, the chosen parameters \\n   most likely prevented these convergence issues.\\n\\n2. Which kernel(s) led to the best performance? Would you expect this always to be the case?\\n\\n   The linear and polynomial kernels with degree = 1 showed the best performance, both achieving an accuracy of 0.9692 along with \\n   high and balanced precision, recall, and F1 scores (around 0.9785). As answered in the next question these two type of models \\n   actually behave the same. These kernals were best due to the data's decision boundary aligning well with a linear. However, for \\n   more complex, non-linear data patterns, the RBF or sigmoid kernels may perform better. So, while linear or polynomial kernels worked \\n   best here, this may not always be the case for all data.\\n\\n3. Does the polynomial kernel with degree=1 behave the same as the linear kernel? Why or why not?\\n\\n   Yes, the polynomial kernel with degree = 1 behaves the same as the linear kernel. With degree = 1, the polynomial kernel \\n   creates a linear decision boundary, which is basically the same to that of the linear kernel. Therefore, both kernels produced \\n   the same performance results, as they both model linear relationships. \\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Did your code produce any warnings? What were they? \n",
    "   Why do you think this may have happened for some models but not for others?\n",
    "\n",
    "   The code did not produce any warnings for me. This suggests that all kernels and parameter ranges were compatible with \n",
    "   the dataset and my device, allowing the models to converge without any visible issues. Warnings might typically occur if a model struggles \n",
    "   with complex boundaries (like higher-degree polynomial kernels), but here, the chosen parameters \n",
    "   most likely prevented these convergence issues.\n",
    "\n",
    "2. Which kernel(s) led to the best performance? Would you expect this always to be the case?\n",
    "\n",
    "   The linear and polynomial kernels with degree = 1 showed the best performance, both achieving an accuracy of 0.9692 along with \n",
    "   high and balanced precision, recall, and F1 scores (around 0.9785). As answered in the next question these two type of models \n",
    "   actually behave the same. These kernals were best due to the data's decision boundary aligning well with a linear. However, for \n",
    "   more complex, non-linear data patterns, the RBF or sigmoid kernels may perform better. So, while linear or polynomial kernels worked \n",
    "   best here, this may not always be the case for all data.\n",
    "\n",
    "3. Does the polynomial kernel with degree=1 behave the same as the linear kernel? Why or why not?\n",
    "\n",
    "   Yes, the polynomial kernel with degree = 1 behaves the same as the linear kernel. With degree = 1, the polynomial kernel \n",
    "   creates a linear decision boundary, which is basically the same to that of the linear kernel. Therefore, both kernels produced \n",
    "   the same performance results, as they both model linear relationships. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8baebea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
